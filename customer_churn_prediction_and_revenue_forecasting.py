# -*- coding: utf-8 -*-
"""Customer Churn Prediction and Revenue Forecasting

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PdRiLAl7hFaxFu2muBpo-qBSdmov-M1K
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

Customers = pd.read_csv("/content/Customers.csv")

Subscriptions = pd.read_csv("/content/Subscription.csv")

Transactions = pd.read_csv("/content/Transcation.csv")

Usage = pd.read_csv("/content/Usage.csv")

merged_df = pd.merge(Customers, Subscriptions, on="CustomerID", how="left")

merged_df = merged_df.merge(Transactions, on="CustomerID", how="left")

merged_df = merged_df.merge(Usage, on="CustomerID", how="left")

# Check for non-datetime values
print(merged_df[["StartDate", "EndDate"]].dtypes)

# Look for rows with invalid dates
print(merged_df[merged_df["StartDate"].isna() | merged_df["EndDate"].isna()])

print(merged_df.columns)

merged_df["StartDate"] = pd.to_datetime(merged_df["StartDate"], errors="coerce")
merged_df["EndDate"] = pd.to_datetime(merged_df["EndDate"], errors="coerce")
merged_df["tenure"] = (merged_df["EndDate"] - merged_df["StartDate"]).dt.days

print(merged_df[["StartDate", "EndDate", "tenure"]].head())

# Avoid division by zero by replacing tenure of 0 with NaN
merged_df["tenure"] = merged_df["tenure"].replace(0, np.nan)

# Calculate average monthly spend
merged_df["average_monthly_spend"] = merged_df["amount"] / (merged_df["tenure"] / 30.0)

# Fill NaN values in 'average_monthly_spend' if any tenure is missing or invalid
merged_df["average_monthly_spend"].fillna(0, inplace=True)

print(merged_df.columns)

print(merged_df.head())

plt.figure(figsize=(8, 5))
sns.histplot(merged_df["Age"], bins=10, kde=True)
plt.title("Age Distribution")
plt.show()

Subscriptions = pd.read_csv("/content/Subscription.csv")
print(Subscriptions.columns)
plt.figure(figsize=(8, 5))
sns.countplot(x="Status", data=Subscriptions)
plt.title("Subscriptions Status")
plt.show()

print(Subscriptions.columns)

plt.figure(figsize=(8, 5))
sns.countplot(x="transaction_type", data=Transactions)
plt.title("Transaction Types")
plt.show()

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Print columns to inspect available ones
print(merged_df.columns)

# Apply label encoding with correct column names
merged_df["Gender"] = LabelEncoder().fit_transform(merged_df["Gender"])
merged_df["Location"] = LabelEncoder().fit_transform(merged_df["Location"])

# Use the correct column names based on your DataFrame
merged_df["SubscriptionID"] = LabelEncoder().fit_transform(merged_df["SubscriptionID"])  # If you need to encode SubscriptionID
merged_df["transaction_type"] = LabelEncoder().fit_transform(merged_df["transaction_type"])  # Encoding for transaction_type



# Check column names to make sure 'churned' is present
print(merged_df.columns)

# If 'churned' column doesn't exist, create it
if 'churned' not in merged_df.columns:
    merged_df["churned"] = (merged_df["Status"] == "Churned").astype(int)

# Define features and target variable
features = ["Age", "Gender", "Income", "tenure", "average_monthly_spend"]
X = merged_df[features]
y = merged_df["churned"]

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.impute import SimpleImputer
from sklearn.cluster import KMeans

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Evaluate model
predictions = model.predict(X_test)
print(classification_report(y_test, predictions))

from sklearn.impute import SimpleImputer

# Create an imputer to fill missing values with the mean
imputer = SimpleImputer(strategy='mean')

# Impute the missing values in X
X_imputed = imputer.fit_transform(X)

# Perform clustering on the cleaned data
kmeans = KMeans(n_clusters=3, random_state=42)
merged_df["segment"] = kmeans.fit_predict(X_imputed)

# Analyze clusters
for segment in merged_df["segment"].unique():
    print(merged_df[merged_df["segment"] == segment].describe())

Transactions["transaction_date"] = pd.to_datetime(Transactions["transaction_date"])

!pip install prophet
# Import the Prophet class
from prophet import Prophet

# Prepare revenue data
revenue_data = Transactions.groupby(Transactions["transaction_date"].dt.to_period("M"))["amount"].sum().reset_index()
revenue_data.columns = ["ds", "y"]
revenue_data["ds"] = revenue_data["ds"].dt.to_timestamp()

# Fit Prophet model
model = Prophet()
model.fit(revenue_data)

# Forecast revenue
future = model.make_future_dataframe(periods=12, freq="M")
forecast = model.predict(future)
model.plot(forecast)
plt.show()

merged_df.to_csv("customer_analysis_results.csv", index=False)
forecast.to_csv("revenue_forecast.csv", index=False)

